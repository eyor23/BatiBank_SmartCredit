{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'futurewarning')\n",
    "from src.woe import calculate_woe_iv, apply_woe_binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_balanced = pd.read_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\train_balanced.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = train_balanced.drop('FraudResult', axis=1)\n",
    "y_train = train_balanced['FraudResult']\n",
    "X_test = test.drop('FraudResult', axis=1)\n",
    "y_test = test['FraudResult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Default Estimator on Original Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier (Baseline):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19097\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           1.00     19133\n",
      "   macro avg       0.50      0.50      0.50     19133\n",
      "weighted avg       1.00      1.00      1.00     19133\n",
      "\n",
      "ROC-AUC: 0.5\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_predictions = dummy_clf.predict(X_test)\n",
    "print(\"Dummy Classifier (Baseline):\\n\", classification_report(y_test, dummy_predictions))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, dummy_clf.predict_proba(X_test)[:, 1]))\n",
    "print(\"F1-score:\", f1_score(y_test, dummy_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression (Default):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     19097\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.95     19133\n",
      "   macro avg       0.50      0.47      0.49     19133\n",
      "weighted avg       1.00      0.95      0.97     19133\n",
      "\n",
      "ROC-AUC: 0.4737131486620935\n",
      "F1-score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (Default)\n",
    "lr_default = LogisticRegression(random_state=42, solver='liblinear')\n",
    "lr_default.fit(X_train, y_train)\n",
    "lr_default_predictions = lr_default.predict(X_test)\n",
    "print(\"\\nLogistic Regression (Default):\\n\", classification_report(y_test, lr_default_predictions))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, lr_default.predict_proba(X_test)[:, 1]))\n",
    "print(\"F1-score:\", f1_score(y_test, lr_default_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **WoE Binning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.qcut(X_train['Amount'], q=10, duplicates='drop')\n",
    "X_train['Amount_bins'] = pd.cut(X_train['Amount'], bins=bins.cat.categories, include_lowest=True)\n",
    "X_test['Amount_bins'] = pd.cut(X_test['Amount'], bins=bins.cat.categories, include_lowest=True)\n",
    "woe_amount = calculate_woe_iv(pd.concat([X_train, y_train], axis=1), 'Amount_bins', 'FraudResult')\n",
    "X_train = apply_woe_binning(X_train, 'Amount_bins', 'FraudResult', woe_amount)\n",
    "X_test = apply_woe_binning(X_test, 'Amount_bins', 'FraudResult', woe_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical_cols.remove('Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    bins = pd.qcut(X_train[col], q=10, duplicates='drop')\n",
    "    X_train[col + '_bins'] = pd.cut(X_train[col], bins=bins.cat.categories, include_lowest=True)\n",
    "    X_test[col + '_bins'] = pd.cut(X_test[col], bins=bins.cat.categories, include_lowest=True)\n",
    "    woe_col = calculate_woe_iv(pd.concat([X_train, y_train], axis=1), col + '_bins', 'FraudResult')\n",
    "    X_train = apply_woe_binning(X_train, col + '_bins', 'FraudResult', woe_col)\n",
    "    X_test = apply_woe_binning(X_test, col + '_bins', 'FraudResult', woe_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original columns and bins\n",
    "cols_to_drop = [col for col in X_train.columns if col.endswith('_bins') or col in numerical_cols]\n",
    "X_train = X_train.drop(cols_to_drop, axis=1)\n",
    "X_test = X_test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute NaN values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape AFTER SMOTE (152744, 20)\n",
      "X_test shape AFTER SMOTE (19133, 20)\n",
      "y_train shape AFTER SMOTE (152744,)\n",
      "y_test shape AFTER SMOTE (19133,)\n",
      "y_train value counts AFTER SMOTE:\n",
      " FraudResult\n",
      "0    76372\n",
      "1    76372\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Debugging: Print shapes and class distribution AFTER SMOTE\n",
    "print('X_train shape AFTER SMOTE', X_train.shape)\n",
    "print('X_test shape AFTER SMOTE', X_test.shape)\n",
    "print('y_train shape AFTER SMOTE', y_train.shape)\n",
    "print('y_test shape AFTER SMOTE', y_test.shape)\n",
    "print('y_train value counts AFTER SMOTE:\\n', pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save WoE-transformed data (ONLY ONCE, AFTER SMOTE)\n",
    "X_train.to_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\X_train_woe.csv', index=False)\n",
    "X_test.to_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\X_test_woe.csv', index=False)\n",
    "y_train.to_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\y_train.csv', index=False)\n",
    "y_test.to_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\y_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Default Estimator on WoE Transformed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dummy Classifier (Baseline - WoE Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19097\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           1.00     19133\n",
      "   macro avg       0.50      0.50      0.50     19133\n",
      "weighted avg       1.00      1.00      1.00     19133\n",
      "\n",
      "ROC-AUC: 0.5\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_woe = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_woe.fit(X_train, y_train)\n",
    "dummy_predictions_woe = dummy_clf_woe.predict(X_test)\n",
    "print(\"\\nDummy Classifier (Baseline - WoE Data):\\n\", classification_report(y_test, dummy_predictions_woe))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, dummy_clf_woe.predict_proba(X_test)[:, 1]))\n",
    "print(\"F1-score:\", f1_score(y_test, dummy_predictions_woe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression (Default - WoE Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57     19097\n",
      "           1       0.00      1.00      0.01        36\n",
      "\n",
      "    accuracy                           0.40     19133\n",
      "   macro avg       0.50      0.70      0.29     19133\n",
      "weighted avg       1.00      0.40      0.57     19133\n",
      "\n",
      "ROC-AUC: 0.7000837827931088\n",
      "F1-score: 0.006244037811117856\n"
     ]
    }
   ],
   "source": [
    "lr_default_woe = LogisticRegression(random_state=42, solver='liblinear')\n",
    "lr_default_woe.fit(X_train, y_train)\n",
    "lr_default_predictions_woe = lr_default_woe.predict(X_test)\n",
    "print(\"\\nLogistic Regression (Default - WoE Data):\\n\", classification_report(y_test, lr_default_predictions_woe))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, lr_default_woe.predict_proba(X_test)[:, 1]))\n",
    "print(\"F1-score:\", f1_score(y_test, lr_default_predictions_woe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summary of Results**:\n",
    "\n",
    "# **Default Estimator (Original Data)**:\n",
    "\n",
    "The Dummy Classifier and default Logistic Regression both demonstrated a strong bias towards the majority class (Non-Fraud).\n",
    "They achieved high accuracy, but this was misleading due to the severe class imbalance.\n",
    "Critically, they failed to detect any fraud cases, resulting in zero precision, recall, and F1-score for the Fraud class.\n",
    "ROC-AUC was at or below 0.5 indicating no predictive power.\n",
    "\n",
    "# **WoE Transformation**:\n",
    "\n",
    "The WoE transformation successfully converted numerical features into a format that reflects their predictive power concerning fraud.\n",
    "The calculated IV values provided insights into the importance of each feature bin.\n",
    "The WoE transformation had a dramatic affect on the logistic regression.\n",
    "\n",
    "# **Default Estimator (WoE Data)**:\n",
    "\n",
    "The Logistic Regression model trained on WoE-transformed data showed a significant shift in behavior.\n",
    "It achieved perfect recall for the Fraud class, meaning it captured all fraud cases.\n",
    "However, this came at the cost of extremely low precision, indicating a high number of false positives.\n",
    "ROC-AUC improved greatly.\n",
    "This indicates the model is now over predicting fraud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
