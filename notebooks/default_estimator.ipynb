{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore','futurewarning')\n",
    "\n",
    "# User-defined modules\n",
    "from src.woe import calculate_woe_iv, apply_woe_binning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_balanced = pd.read_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\train_balanced.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = train_balanced.drop('FraudResult', axis=1)\n",
    "y_train = train_balanced['FraudResult']\n",
    "X_test = test.drop('FraudResult', axis=1)\n",
    "y_test = test['FraudResult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Default Estimator on Original Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier (Baseline):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19097\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           1.00     19133\n",
      "   macro avg       0.50      0.50      0.50     19133\n",
      "weighted avg       1.00      1.00      1.00     19133\n",
      "\n",
      "ROC-AUC: 0.5\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Dummy Classifier (Baseline)\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_predictions = dummy_clf.predict(X_test)\n",
    "\n",
    "print(\"Dummy Classifier (Baseline):\")\n",
    "print(classification_report(y_test, dummy_predictions))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, dummy_clf.predict_proba(X_test)[:, 1]))\n",
    "print(\"F1-score:\", f1_score(y_test, dummy_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression (Default):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     19097\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.95     19133\n",
      "   macro avg       0.50      0.47      0.49     19133\n",
      "weighted avg       1.00      0.95      0.97     19133\n",
      "\n",
      "ROC-AUC: 0.4737131486620935\n",
      "F1-score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (Default)\n",
    "lr_default = LogisticRegression(random_state=42, solver='liblinear') #liblinear handles small datasets better.\n",
    "lr_default.fit(X_train, y_train)\n",
    "lr_default_predictions = lr_default.predict(X_test)\n",
    "\n",
    "print(\"\\nLogistic Regression (Default):\")\n",
    "print(classification_report(y_test, lr_default_predictions))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, lr_default.predict_proba(X_test)[:, 1]))\n",
    "print(\"F1-score:\", f1_score(y_test, lr_default_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **WoE Binning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins\n",
    "bins = pd.qcut(X_train['Amount'], q=10, duplicates='drop') # 10 bins\n",
    "\n",
    "# Apply bins to both train and test\n",
    "X_train['Amount_bins'] = pd.cut(X_train['Amount'], bins=bins.cat.categories, include_lowest=True)\n",
    "X_test['Amount_bins'] = pd.cut(X_test['Amount'], bins=bins.cat.categories, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WoE and IV for Amount:\n",
      "                Value    All   Good    Bad        Good %     Bad %        WoE  \\\n",
      "0  (-0.0569, -0.0558]  16376  16358     18  9.989008e-01  0.001099   6.812101   \n",
      "1    (-0.0273, 0.107]  15779  15684     95  9.939793e-01  0.006021   5.106519   \n",
      "2  (-0.0558, -0.0475]  20358  20272     86  9.957756e-01  0.004224   5.462649   \n",
      "3   (-8.167, -0.0569]  15068  13065   2003  8.670693e-01  0.132931   1.875291   \n",
      "4        (0.107, 4.0]  22457   2139  20318  9.524870e-02  0.904751  -2.251169   \n",
      "5  (-0.0475, -0.0273]   8825   8807     18  9.979603e-01  0.002040   6.192930   \n",
      "6     (6.343, 21.907]  15273     47  15226  3.077326e-03  0.996923  -5.780612   \n",
      "7    (21.907, 80.075]  15271      0  15271  6.548360e-11  1.000000 -23.449221   \n",
      "8        (4.0, 4.414]   8060      0   8060  1.240695e-10  1.000000 -22.810179   \n",
      "9      (4.414, 6.343]  15273      0  15273  6.547502e-11  1.000000 -23.449352   \n",
      "\n",
      "          IV  \n",
      "0   6.797125  \n",
      "1   5.045030  \n",
      "2   5.416496  \n",
      "3   1.376723  \n",
      "4   1.822327  \n",
      "5   6.167667  \n",
      "6   5.745034  \n",
      "7  23.449221  \n",
      "8  22.810179  \n",
      "9  23.449352  \n"
     ]
    }
   ],
   "source": [
    "# Calculate WoE and IV\n",
    "woe_amount = calculate_woe_iv(pd.concat([X_train, y_train], axis=1), 'Amount_bins', 'FraudResult')\n",
    "print(\"\\nWoE and IV for Amount:\")\n",
    "print(woe_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply WoE transformation\n",
    "X_train = apply_woe_binning(X_train, 'Amount_bins', 'FraudResult', woe_amount)\n",
    "X_test = apply_woe_binning(X_test, 'Amount_bins', 'FraudResult', woe_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to all other relevant columns\n",
    "numerical_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical_cols.remove('Amount') #original amount column\n",
    "\n",
    "for col in numerical_cols:\n",
    "    bins = pd.qcut(X_train[col], q=10, duplicates='drop')\n",
    "    X_train[col + '_bins'] = pd.cut(X_train[col], bins=bins.cat.categories, include_lowest=True)\n",
    "    X_test[col + '_bins'] = pd.cut(X_test[col], bins=bins.cat.categories, include_lowest=True)\n",
    "\n",
    "    woe_col = calculate_woe_iv(pd.concat([X_train, y_train], axis=1), col + '_bins', 'FraudResult')\n",
    "    X_train = apply_woe_binning(X_train, col + '_bins', 'FraudResult', woe_col)\n",
    "    X_test = apply_woe_binning(X_test, col + '_bins', 'FraudResult', woe_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original columns and bins\n",
    "cols_to_drop = [col for col in X_train.columns if '_bins' in col or col in numerical_cols]\n",
    "X_train = X_train.drop(cols_to_drop, axis=1)\n",
    "X_test = X_test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Default Estimator on WoE Transformed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dummy Classifier (Baseline - WoE Data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19097\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           1.00     19133\n",
      "   macro avg       0.50      0.50      0.50     19133\n",
      "weighted avg       1.00      1.00      1.00     19133\n",
      "\n",
      "ROC-AUC: 0.5\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\batvenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Dummy Classifier (Baseline)\n",
    "dummy_clf_woe = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_woe.fit(X_train, y_train)\n",
    "dummy_predictions_woe = dummy_clf_woe.predict(X_test)\n",
    "\n",
    "print(\"\\nDummy Classifier (Baseline - WoE Data):\")\n",
    "print(classification_report(y_test, dummy_predictions_woe))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, dummy_clf_woe.predict_proba(X_test)[:, 1]))\n",
    "print(\"F1-score:\", f1_score(y_test, dummy_predictions_woe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression (Default - WoE Data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57     19097\n",
      "           1       0.00      1.00      0.01        36\n",
      "\n",
      "    accuracy                           0.40     19133\n",
      "   macro avg       0.50      0.70      0.29     19133\n",
      "weighted avg       1.00      0.40      0.57     19133\n",
      "\n",
      "ROC-AUC: 0.7000837827931089\n",
      "F1-score: 0.006244037811117856\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (Default)\n",
    "lr_default_woe = LogisticRegression(random_state=42, solver='liblinear')\n",
    "lr_default_woe.fit(X_train, y_train)\n",
    "lr_default_predictions_woe = lr_default_woe.predict(X_test)\n",
    "\n",
    "print(\"\\nLogistic Regression (Default - WoE Data):\")\n",
    "print(classification_report(y_test, lr_default_predictions_woe))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, lr_default_woe.predict_proba(X_test)[:, 1]))\n",
    "print(\"F1-score:\", f1_score(y_test, lr_default_predictions_woe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\X_train_woe.csv', index=False)\n",
    "X_test.to_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\X_test_woe.csv', index=False)\n",
    "y_train.to_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\y_train.csv', index=False)\n",
    "y_test.to_csv(r'C:\\Users\\user\\Desktop\\BatiBank_SmartCredit\\data\\y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summary of Results**:\n",
    "\n",
    "# **Default Estimator (Original Data)**:\n",
    "\n",
    "The Dummy Classifier and default Logistic Regression both demonstrated a strong bias towards the majority class (Non-Fraud).\n",
    "They achieved high accuracy, but this was misleading due to the severe class imbalance.\n",
    "Critically, they failed to detect any fraud cases, resulting in zero precision, recall, and F1-score for the Fraud class.\n",
    "ROC-AUC was at or below 0.5 indicating no predictive power.\n",
    "\n",
    "# **WoE Transformation**:\n",
    "\n",
    "The WoE transformation successfully converted numerical features into a format that reflects their predictive power concerning fraud.\n",
    "The calculated IV values provided insights into the importance of each feature bin.\n",
    "The WoE transformation had a dramatic affect on the logistic regression.\n",
    "\n",
    "# **Default Estimator (WoE Data)**:\n",
    "\n",
    "The Logistic Regression model trained on WoE-transformed data showed a significant shift in behavior.\n",
    "It achieved perfect recall for the Fraud class, meaning it captured all fraud cases.\n",
    "However, this came at the cost of extremely low precision, indicating a high number of false positives.\n",
    "ROC-AUC improved greatly.\n",
    "This indicates the model is now over predicting fraud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
